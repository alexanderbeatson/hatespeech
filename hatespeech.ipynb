{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hatespeech.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpTvpvZjdBEa",
        "colab_type": "text"
      },
      "source": [
        "# Hatespeech research\n",
        "This script is made to clean and aggregate the data automatically. \n",
        "Script environment is python with R extension.\n",
        "You need to upload the data to your Google drive and connect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrFbe02b3KKr",
        "colab_type": "text"
      },
      "source": [
        "Firstly I'll load the R environment from Python runtime. Mount Google drive and install the necessary packages and load them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzgdp41Vb9xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext rpy2.ipython\n",
        "#Load R extension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1HlbHZcwk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive #Mount G-drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E2FPKNvi6IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "library (tidyverse)\n",
        "install.packages(c(\"openxlsx\",\"data.table\"))\n",
        "library (openxlsx)\n",
        "library (data.table)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glwrv45JsPS2",
        "colab_type": "text"
      },
      "source": [
        "* Filter and sample the data from the CrowdTangle. \n",
        "* CTHP data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdUejkseLSHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "master_dir <- \"/content/drive/'My Drive'/hatespeech/CTHP/\"\n",
        "Today <- format(Sys.time(), \"D%dM%m\")\n",
        "system(\"mkdir /content/hs\")\n",
        "cdir <- \"/content/hs/\"\n",
        "system(paste0(\"cp \",master_dir,Today,\".csv \",cdir))\n",
        "CTHP <- read.csv (paste0(cdir,Today,\".csv\"), stringsAsFactors = F)\n",
        "CTHP <- CTHP %>% filter (Comments >= 100) %>% mutate (prob = Comments/sum(Comments))\n",
        "if (nrow(CTHP) > 100) {\n",
        "    lexicon <- read.csv (\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTyhO1LfxmVwkA_6QJnGRlV0Y0269WMcOnJymkA6ropJZH5i29Ob56rNuAWYwv4aAakXjsiqOBET2Gn/pub?gid=2071343638&single=true&output=csv\", stringsAsFactors = F)\n",
        "    lexicon <- unlist(lexicon)\n",
        "    hs_row <- NULL\n",
        "    for (i in 1:nrow(CTHP)) {\n",
        "        hs_row[i] <- any(str_detect(CTHP[i,\"Description\"],lexicon))\n",
        "    }\n",
        "    hs_row[is.na(hs_row)] <- F\n",
        "    if (sum(hs_row) > 100) {\n",
        "        CTHP <- CTHP[hs_row,]\n",
        "        CTHP <- CTHP[sample(1:nrow(CTHP),100, prob = CTHP$prob),]\n",
        "    } else {\n",
        "        CTU <- CTHP[!hs_row,]\n",
        "        CTHP <- rbind.data.frame(CTU[sample(1:nrow(CTU),(100-sum(hs_row)),prob = CTU$prob),],CTHP[hs_row,])\n",
        "    }\n",
        "}\n",
        "system(\"mkdir sample\")\n",
        "write.csv(CTHP, paste0(\"./sample/\",Today,\".csv\"), row.names = F)\n",
        "system(paste0(\"mv ./sample/\",Today,\".csv /content/drive/'My Drive'/hatespeech/CTHP/sample/\"))\n",
        "system(paste0(\"rm \",cdir,Today,\".csv\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um5s08-y3iOA",
        "colab_type": "text"
      },
      "source": [
        "This section copy the data from the Google drive to the local runtime. (This step is crucial because we cannot load the data directly from the Google drive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtKEkDM4kmm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%R\n",
        "wdir <- paste0(\"./drive/'My Drive'/hatespeech/Post/\", Today)\n",
        "system(paste0(\"cp \", wdir, \"/* \", cdir))\n",
        "item_list <- system(paste(\"ls\",cdir), intern = T)\n",
        "TD_data <- data.table()\n",
        "smp_func <- function (s = 5) {\n",
        "  for (i in 1:length(item_list)) {\n",
        "    assign(paste0(\"docs\",i), read.xlsx(paste0(cdir,item_list[i]), sheet = 1, startRow = 6, colNames = T, detectDates = T))\n",
        "    unirl <- read.xlsx(paste0(cdir,item_list[i]), sheet = 1, rows = 2, cols = 2, colNames = F)\n",
        "    unirl <- unlist(unirl)\n",
        "    temp_df <- eval(as.name(paste0(\"docs\",i)))\n",
        "    temp_df <- temp_df[sample(nrow(temp_df),s, prob = temp_df$prob),]\n",
        "    temp_df$url <- unirl\n",
        "    TD_data <- rbind.data.frame(TD_data,temp_df)\n",
        "    rm(temp_df)\n",
        "  }\n",
        "  return(TD_data)\n",
        "}\n",
        "if (length(item_list)< 100) {\n",
        "    s = ceiling(500/length(item_list))\n",
        "    TD_data <- smp_func(s = s)\n",
        "    TD_data <- TD_data [sample(nrow(TD_data), 500),]\n",
        "} else {\n",
        "  TD_data <- smp_func()\n",
        "}\n",
        "\n",
        "write.csv(TD_data, paste0(cdir,\"C\",Today,\".csv\"), row.names = F)\n",
        "system(paste0(\"mv \",cdir,\"C\",Today,\".csv /content/drive/'My Drive'/hatespeech/Post/\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}